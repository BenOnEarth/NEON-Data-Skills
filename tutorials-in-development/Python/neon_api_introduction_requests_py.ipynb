{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "syncID: \n",
    "title: \"Introduction to NEON API in Python\"\n",
    "description: \"Use the NEON API in Python, via requests package and json package.\"\n",
    "dateCreated: 2020-04-24\n",
    "authors: Maxwell J. Burner\n",
    "contributors: \n",
    "estimatedTime:\n",
    "packagesLibraries: requests, json\n",
    "topics: api\n",
    "languagesTool: python\n",
    "dataProduct: DP3.30015.001\n",
    "code1: \n",
    "tutorialSeries: python-neon-api-series\n",
    "urlTitle: neon_api_introduction_requests\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to NEON API with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will use Python to make requests/calls to the NEON API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"ds-objectives\" markdown=\"1\">\n",
    "\n",
    "### Objectives\n",
    "After completing this tutorial, you will be able to:\n",
    "\n",
    "* Understand the components of a NEON API call\n",
    "* Understand the basic process of making and processing an API request in Python\n",
    "* Query the 'sites/' or 'products/' API endpoints to determine data availability\n",
    "* Query the 'data/' API endpoint to get information on specific data files\n",
    "\n",
    "\n",
    "### Install Python Packages\n",
    "\n",
    "* **requests**\n",
    "* **json** \n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will learn to make calls to the NEON API using Python. We will make calls to the 'sites/' and 'products/' endpoints of the API to determine availability of data for specific sites and months, and make a call to the 'data/' endpoint to learn the names and URLs of specific data files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic API Call Components\n",
    "\n",
    "The actual API call takes the form of a web URL, the contents of which determine what data is returned. This URL can be broken down into three parts, which appear in order:\n",
    "\n",
    "- The **base url** is the location of the server storing the data. This will be the same for all NEON API calls.\n",
    "\n",
    "- The **endpoint** indicates what type of data or metadata we are looking to download. This tutorial covers three endpoints: *sites/*, *products/*, and *data/*; other endpoints will be covered in later tutorials.\n",
    "\n",
    "- The **target** is a value or series of values that indicate the specific data product, site, location, or data files we are looking up.\n",
    "\n",
    "\n",
    "\n",
    "In python we can easily deal with the complexities of the API call with by creating the different parts of the request as strings, then combining them with string concatenation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Every request begins with the server's URL\n",
    "SERVER = 'http://data.neonscience.org/api/v0/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site Querying\n",
    "\n",
    "Often we begin by asking what kinds of data products are available for a given site. This is done by using the 'sites/' endpoint in the API; this endpoint is used for getting information about specific NEON field sites. In this example we check what data products are available at the Lower Teakettle site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Site Code for Lower Teakettle\n",
    "SITECODE = 'TEAK'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first use the requests module to send the API request using the 'get' function; this returns a 'request' object. To more easily access the data returned by the request, we convert teh request object into a Python JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make request, using the sites/ endpoint\n",
    "site_request = requests.get(SERVER+'sites/'+SITECODE)\n",
    "\n",
    "#Convert to Python JSON object\n",
    "site_json = site_request.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The JSON object in Python is a complex collection, with nested layers of dictionaries and lists. Briefly, a list is a collection in which each element is identified by index number, while a dictionary is a collection in which each element is identified by a label (called a 'key') that is usually text.\n",
    "\n",
    "At the uppermost level the JSON object is a dictionary containing a single element with the label \"data\". This data element in turn contains a dictionary with elements containing various pieces of information about the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['siteDescription', 'siteLongitude', 'siteType', 'stateName', 'stateCode', 'siteLatitude', 'domainName', 'domainCode', 'siteCode', 'dataProducts', 'siteName'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the 'keys' method to view to componenets of the json data dictionary\n",
    "site_json['data'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned JSON includes information on site location, site type, site name and code, and the availability of different data products for the site. This last piece of information is located in the dctiomnary element with the 'dataProducts' key.\n",
    "\n",
    "The 'dataProducts' element is a list of dictionaries one for each type of NEON data product available at the site; each of these dictionaries has the same keys, but different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View keys of a data product dictionary\n",
    "site_json['data']['dataProducts'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP1.00001.001 2D wind speed and direction\n",
      "DP1.00002.001 Single aspirated air temperature\n",
      "DP1.00003.001 Triple aspirated air temperature\n",
      "DP1.00004.001 Barometric pressure\n",
      "DP1.00005.001 IR biological temperature\n",
      "DP1.00006.001 Precipitation\n",
      "DP1.00014.001 Shortwave radiation (direct and diffuse pyranometer)\n",
      "DP1.00023.001 Shortwave and longwave radiation (net radiometer)\n",
      "DP1.00024.001 Photosynthetically active radiation (PAR)\n",
      "DP1.00033.001 Phenology images\n",
      "DP1.00040.001 Soil heat flux plate\n",
      "DP1.00041.001 Soil temperature\n",
      "DP1.00042.001 Snow depth and understory phenology images\n",
      "DP1.00066.001 Photosynthetically active radiation (quantum line)\n",
      "DP1.00094.001 Soil water content and water salinity\n",
      "DP1.00095.001 Soil CO2 concentration\n",
      "DP1.00096.001 Soil physical properties (Megapit)\n",
      "DP1.00097.001 Soil chemical properties (Megapit)\n",
      "DP1.00098.001 Relative humidity\n",
      "DP1.10003.001 Breeding landbird point counts\n",
      "DP1.10017.001 Digital hemispheric photos of plot vegetation\n",
      "DP1.10022.001 Ground beetles sampled from pitfall traps\n",
      "DP1.10023.001 Herbaceous clip harvest\n",
      "DP1.10033.001 Litterfall and fine woody debris sampling\n",
      "DP1.10043.001 Mosquitoes sampled from CO2 traps\n",
      "DP1.10045.001 Non-herbaceous perennial vegetation structure\n",
      "DP1.10055.001 Plant phenology observations\n",
      "DP1.10058.001 Plant presence and percent cover\n",
      "DP1.10064.001 Rodent-borne pathogen status\n",
      "DP1.10066.001 Root sampling (Megapit)\n",
      "DP1.10072.001 Small mammal box trapping\n",
      "DP1.10076.001 Small mammal sequences DNA barcode\n",
      "DP1.10086.001 Soil physical properties (Distributed periodic)\n",
      "DP1.10093.001 Ticks sampled using drag cloths\n",
      "DP1.10098.001 Woody plant vegetation structure\n",
      "DP1.10099.001 Root stable isotopes\n",
      "DP1.10102.001 Root chemical properties\n",
      "DP1.10111.001 Site management and event reporting\n",
      "DP1.30001.001 LiDAR slant range waveform\n",
      "DP1.30003.001 Discrete return LiDAR point cloud\n",
      "DP1.30006.001 Spectrometer orthorectified surface directional reflectance - flightline\n",
      "DP1.30008.001 Spectrometer orthrorectified at-sensor radiance - flightline\n",
      "DP1.30010.001 High-resolution orthorectified camera imagery\n",
      "DP2.30011.001 Albedo - spectrometer - flightline\n",
      "DP2.30012.001 LAI - spectrometer - flightline\n",
      "DP2.30014.001 fPAR - spectrometer - flightline\n",
      "DP2.30016.001 Total biomass map - spectrometer - flightline\n",
      "DP2.30018.001 Canopy nitrogen - flightline\n",
      "DP2.30019.001 Canopy water content - flightline\n",
      "DP2.30020.001 Canopy xanthophyll cycle - flightline\n",
      "DP2.30022.001 Canopy lignin - flightline\n",
      "DP2.30026.001 Vegetation indices - spectrometer - flightline\n",
      "DP3.30006.001 Spectrometer orthorectified surface directional reflectance - mosaic\n",
      "DP3.30010.001 High-resolution orthorectified camera imagery mosaic\n",
      "DP3.30011.001 Albedo - spectrometer - mosaic\n",
      "DP3.30012.001 LAI - spectrometer - mosaic\n",
      "DP3.30014.001 fPAR - spectrometer - mosaic\n",
      "DP3.30015.001 Ecosystem structure\n",
      "DP3.30016.001 Total biomass map - spectrometer - mosaic\n",
      "DP3.30018.001 Canopy nitrogen - mosaic\n",
      "DP3.30019.001 Canopy water content - mosaic\n",
      "DP3.30020.001 Canopy xanthophyll cycle - mosaic\n",
      "DP3.30022.001 Canopy lignin - mosaic\n",
      "DP3.30024.001 Elevation - LiDAR\n",
      "DP3.30025.001 Slope and Aspect - LiDAR\n",
      "DP3.30026.001 Vegetation indices - spectrometer - mosaic\n",
      "DP4.00200.001 Bundled data products - eddy covariance\n"
     ]
    }
   ],
   "source": [
    "#View product code and name for every available data product\n",
    "for product in site_json['data']['dataProducts']:\n",
    "    print(product['dataProductCode'],product['dataProductTitle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, we use site queries to determine for which months a particular data product is available at a particular site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at Ecosystem structure data products\n",
    "PRODUCTCODE = 'DP3.30015.001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Months:  ['2013-06', '2017-06', '2018-06', '2019-06']\n",
      "URLs for each Month:  ['https://data.neonscience.org/api/v0/data/DP3.30015.001/TEAK/2013-06', 'https://data.neonscience.org/api/v0/data/DP3.30015.001/TEAK/2017-06', 'https://data.neonscience.org/api/v0/data/DP3.30015.001/TEAK/2018-06', 'https://data.neonscience.org/api/v0/data/DP3.30015.001/TEAK/2019-06']\n"
     ]
    }
   ],
   "source": [
    "#Get available months of ecosytem structure data products for TEAK site\n",
    "for product in site_json['data']['dataProducts']:\n",
    "    if(product['dataProductCode'] == PRODUCTCODE):\n",
    "        print('Available Months: ',product['availableMonths'])\n",
    "        print('URLs for each Month: ', product['availableDataUrls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Product Querying\n",
    "\n",
    "Alternately, we may want a specific type of data product, but aren't certain of the sites and months for which that data is available. In this case we can use the product code and the *products/* API endpoint to look up availbility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make request\n",
    "product_request = requests.get(SERVER+'products/'+PRODUCTCODE)\n",
    "product_json = product_request.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product JSON will again store everything first in a 'data' element. Within this container, the product data is a dictionary with information on the data product we are looking up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['productCodeLong', 'productCode', 'productCodePresentation', 'productName', 'productDescription', 'productStatus', 'productCategory', 'productHasExpanded', 'productScienceTeamAbbr', 'productScienceTeam', 'productPublicationFormatType', 'productAbstract', 'productDesignDescription', 'productStudyDescription', 'productBasicDescription', 'productExpandedDescription', 'productSensor', 'productRemarks', 'themes', 'changeLogs', 'specs', 'keywords', 'siteCodes'])\n"
     ]
    }
   ],
   "source": [
    "#Print keys for product data dictionary\n",
    "print(product_json['data'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This request returned a lot of different types of information. Much of this information is meant to provide explanations and context for the data product. Let's look at the abstract, which provides a relatively brief description of the data product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forests store and sequester a considerable proportion of the terrestrial global carbon budget. Forest canopy metrics are directly measurable with LiDAR sensors because laser pulses will be reflected from the uppermost canopy layers and remaining energy will penetrate to, and reflect from, under-story and the ground surface. The near simultaneous direct measurement of ground and canopy elevation allows the canopy height to be estimated through differencing. The CHM is generated by creating a continuous surface of canopy height estimates across the entire spatial domain of the LiDAR survey. The CHM is derived directly from the LiDAR point cloud. The LiDAR point cloud is produced from LiDAR return signals from both surface features and the true-ground as LiDAR pulses will be reflected from the uppermost layers of the canopy, as well as the underlying ground surface. To produce the CHM, the point cloud is separated into classes representing the ground and vegetation returns. The ground classified points allow calculation of a height normalized point cloud to provide a relative estimate of vegetation elevation. A surface is then generated using the height normalized vegetation points to produce the CHM.\n",
      "\n",
      "Latency:\n",
      "AOP data will be available 60 days after the final collection day at a site. AOP legacy data (those collected in 2013 through 2016) currently has partial availability, and will be completely available by April of 2019.\n",
      "\n",
      "*Note: Data are being migrated to the data portal. If you don't find the data you are looking for (e.g., from specific sites or years), please request data [here](http://www.neonscience.org/request-airborne-data).\n"
     ]
    }
   ],
   "source": [
    "print(product_json['data']['productAbstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For looking up the availability of the data product, we want the 'siteCodes' element. This is a list with an entry for each site at which the data product is available. Each site entry is a dict whose elements includes site code, a list of months for which data is available, and a list of the API request URLs to request data for that site for a given month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['siteCode', 'availableMonths', 'availableDataUrls'])\n"
     ]
    }
   ],
   "source": [
    "#View keys of one site dictionary\n",
    "print(product_json['data']['siteCodes'][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look up the availability of data at a particular site, and get a URL to request data for a specific month. We know from earlier that Lower Teakettle has the data product we want for 2018-06; we can get the URL needed to request that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-06 https://data.neonscience.org/api/v0/data/DP3.30015.001/TEAK/2013-06\n",
      "2017-06 https://data.neonscience.org/api/v0/data/DP3.30015.001/TEAK/2017-06\n",
      "2018-06 https://data.neonscience.org/api/v0/data/DP3.30015.001/TEAK/2018-06\n",
      "2019-06 https://data.neonscience.org/api/v0/data/DP3.30015.001/TEAK/2019-06\n"
     ]
    }
   ],
   "source": [
    "#View available months and corresponding API urls, then save desired URL\n",
    "for site in product_json['data']['siteCodes']:\n",
    "    if(site['siteCode'] == SITECODE):\n",
    "        for month in zip(site['availableMonths'],site['availableDataUrls']):\n",
    "            print(month[0],month[1]) \n",
    "            if(month[0] == '2018-06'): #If data is available for the desired month, save the URL\n",
    "                data_url = month[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://data.neonscience.org/api/v0/data/DP3.30015.001/TEAK/2018-06\n"
     ]
    }
   ],
   "source": [
    "print(data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data File Querying\n",
    "\n",
    "We now know that ecosystem structure data products are available for 2019-06 at the Lower Teakettle site. Using the server url, site code, product code, and a year-month argument, we can make a request to the 'data/' endpoint of the NEON API. This will allow us to see what specific ecosystem structure data files can be obtained for 2019-06 at the Lower Teakettle site, and to learn the locations of these files as URLs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Request\n",
    "data_request = requests.get(SERVER+'data/'+PRODUCTCODE+'/'+SITECODE+'/'+'2018-06')\n",
    "data_json = data_request.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately we could use one of the \"Available Data URLs\" from a sites/ or products/ request, like the data_url we saved earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make request with saved url\n",
    "data_request = requests.get(data_url)\n",
    "data_json = data_request.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['files', 'productCode', 'siteCode', 'month'])\n"
     ]
    }
   ],
   "source": [
    "#Print dict key for 'data' element of data JSON\n",
    "print(data_json['data'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the sites JSON, the data request JSON is dictionary whose only member has the 'data' key; this member in turn is a dictionary with the product code, the sitecode, the month, and a list of the available data files.\n",
    "\n",
    "The 'files' list is a list of python dictionaries, one for each file available based on our query; the dictionary for each file includes the ???, the file name, the size of the file in bytes and the url at which the file is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crc32 :\t 81ad6c42\n",
      "name :\t NEON_D17_TEAK_DP1_315000_4090000_classified_point_cloud.shp\n",
      "size :\t 1884\n",
      "url :\t https://neon-aop-products.s3.data.neonscience.org:443/2018/FullSite/D17/2018_TEAK_3/Metadata/DiscreteLidar/TileBoundary/shps/NEON_D17_TEAK_DP1_315000_4090000_classified_point_cloud.shp?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200426T171115Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=pub-internal-read%2F20200426%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=b91cf4cecfd4f1c23de917394e99a19a9d81e367615e01e2dbbd13ba8c8ce7d0\n"
     ]
    }
   ],
   "source": [
    "#View keys and values in first file dict\n",
    "for key in data_json['data']['files'][0].keys():\n",
    "    print(key,':\\t', data_json['data']['files'][0][key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecosystem structure data products include Canopy Height Model (CHM) geoTIFF files; these are the files whose names end with 'CHM.tif'. Let's say we wanted from the start to get the name an url of CHM geoTIFFs for four adjacent tiles, for which we know the coordinates. We can use Pythons 'in' operator and a for loop to search for the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEON_D17_TEAK_DP3_316000_4098000_CHM.tif https://neon-aop-products.s3.data.neonscience.org:443/2018/FullSite/D17/2018_TEAK_3/L3/DiscreteLidar/CanopyHeightModelGtif/NEON_D17_TEAK_DP3_316000_4098000_CHM.tif?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200426T171116Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=pub-internal-read%2F20200426%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=8f6a0d54bc6bf4659ae3b9ee570b66a8d6ad27a3815ed98c212611d74db3c645\n",
      "NEON_D17_TEAK_DP3_316000_4097000_CHM.tif https://neon-aop-products.s3.data.neonscience.org:443/2018/FullSite/D17/2018_TEAK_3/L3/DiscreteLidar/CanopyHeightModelGtif/NEON_D17_TEAK_DP3_316000_4097000_CHM.tif?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200426T171116Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=pub-internal-read%2F20200426%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=66658bc2c18229d8dea383047f1e21b62303906e1218f2bf234cb62cbbba11a2\n",
      "NEON_D17_TEAK_DP3_317000_4098000_CHM.tif https://neon-aop-products.s3.data.neonscience.org:443/2018/FullSite/D17/2018_TEAK_3/L3/DiscreteLidar/CanopyHeightModelGtif/NEON_D17_TEAK_DP3_317000_4098000_CHM.tif?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200426T171116Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=pub-internal-read%2F20200426%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=f610c8f8f901c4be89d88ab2e8b10d3ad97583a7cf583e89413aa9733f0ad9ce\n",
      "NEON_D17_TEAK_DP3_317000_4097000_CHM.tif https://neon-aop-products.s3.data.neonscience.org:443/2018/FullSite/D17/2018_TEAK_3/L3/DiscreteLidar/CanopyHeightModelGtif/NEON_D17_TEAK_DP3_317000_4097000_CHM.tif?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200426T171116Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=pub-internal-read%2F20200426%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=e19239d3dffff331a07cc607274277fcff69d1f6cd672ebecb70077afcd7fce3\n"
     ]
    }
   ],
   "source": [
    "for file in data_json['data']['files']:\n",
    "    if('CHM.tif' in file['name']): #Only get Canopy Height Model geoTIFF files\n",
    "        if(('317000' in file['name'])|('316000' in file['name'])): #Only tiles with x-coordinate 316000 or 317000\n",
    "            if(('4098000' in file['name'])|('4097000' in file['name'])): #Only tiles with y-coordinate 4097000 or 4098000\n",
    "                print(file['name'], file['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can download the desired files by simply going to the obtained URLs in any browser. However, we might want the Python script to download the files for us. Alternately, dependong on the type of file, various funcitons exist that could read data from the file directly into Python. We'll dicuss this more in later tutorials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
